# FILE: ake_substrate_engine.py
# VERSION: v3.0.0
# AUTHOR: Brandon "iambandobandz" Emery Ã— Victor (Fractal Architect Mode) + OmniForge
# --------------------------------------------------------------------------------------
# REALâ€‘WORLD AKE: Neuroâ€‘Symbolic Substrate Engine (ðŸ˜±Â NOÂ MOREÂ SIMULATION)
# --------------------------------------------------------------------------------------
# This release drops the toy dictionary lookup and plugs directly into live generative
# models (OpenAI, Llamaâ€‘CPP, or any localÂ LLM) plus an HTTP API surface so other services
# â€“Â robots, games, AR/VR rigs, knowledge graphs â€“ can query the substrate in real time.
#
# NEWÂ CAPABILITIES
# â€¢ ðŸŒÂ FastAPI server (`--serve`) delivers RESTÂ +Â WebSocket endpoints
# â€¢ ðŸ§ Â Pluggable `TextureProvider` interface with a default OpenAI provider (async)
# â€¢ ðŸ’¾Â SQLModelâ€‘based persistence (SQLite by default) for symbolic objects & scenes
# â€¢ ðŸ”‘Â Config via envÂ vars, `.env`, or YAML/JSON (still supported)
# â€¢ ðŸ”„Â Hotâ€‘reloadable texture pipelines (`POST /materials`) without downtime
# â€¢ ðŸªÂ Event hooks (pre/post render) â€“ simple Python callbacks for IoT or telemetry
# â€¢ ðŸ•¸ï¸Â CORS & HTTPSâ€‘ready; deploy behind any ASGI server (uvicorn, hypercorn)
#
# QUICKSTART
#     pip install "openai>=1,<2" fastapi "uvicorn[standard]" sqlmodel pythonâ€‘dotenv httpx pyyaml
#     export OPENAI_API_KEY="skâ€‘..."  # or add to .env
#     python ake_substrate_engine.py --serve --host 0.0.0.0 --port 8000 -vv
#
# SECURITY NOTE
#     NEVER commit real API keys. This engine reads them from env only.
# --------------------------------------------------------------------------------------
from __future__ import annotations

import argparse
import asyncio
import json
import logging
import os
import random
import sys
from contextlib import asynccontextmanager
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
from typing import Any, Dict, Iterable, List, Mapping, Optional, Protocol, Sequence

import httpx
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, validator
from sqlmodel import Field, SQLModel, create_engine, select, Session

try:
    import yaml  # type: ignore
except ModuleNotFoundError:
    yaml = None  # type: ignore

try:
    from openai import AsyncOpenAI
except ModuleNotFoundError:  # Local dev without OpenAI lib
    AsyncOpenAI = None  # type: ignore

# --------------------------------------------------------------------------------------
# Logging -----------------------------------------------------------------------------
# --------------------------------------------------------------------------------------
LOG_LEVEL_ENV = "AKE_LOG_LEVEL"
DEFAULT_LOG_LEVEL = logging.INFO
logging.basicConfig(
    level=os.getenv(LOG_LEVEL_ENV, DEFAULT_LOG_LEVEL),
    format="[%(levelname)s] %(asctime)s â€‘ %(name)s: %(message)s",
    datefmt="%Yâ€‘%mâ€‘%d %H:%M:%S",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger("AKEâ€‘Engine")

# --------------------------------------------------------------------------------------
# DomainÂ Model (Symbolic) --------------------------------------------------------------
# --------------------------------------------------------------------------------------
class Shape(str, Enum):
    SPHERE = "sphere"
    SLAB = "slab"
    TOROID = "toroid"
    HUMANOID = "humanoid"
    UNKNOWN = "unknown"


class Material(str, Enum):
    CRYSTAL = "crystal"
    STONE = "stone"
    PLASMA = "plasma"
    SILICON = "silicon"
    UNDEFINED = "undefined"


class State(str, Enum):
    ANCIENT = "ancient"
    NEW = "new"
    BROKEN = "broken"
    ACTIVE = "active"
    DEFAULT = "neutral"


@dataclass(slots=True, frozen=True)
class SymbolicObject:
    name: str
    shape: Shape = Shape.UNKNOWN
    material: Material = Material.UNDEFINED
    state: State = State.DEFAULT
    metadata: Mapping[str, Any] = field(default_factory=dict, repr=False)

    def symbolic_str(self) -> str:
        return (
            f"Symbolic ID: {self.name} | Shape: {self.shape.value} | "
            f"Material: {self.material.value} | State: {self.state.value}"
        )

# --------------------------------------------------------------------------------------
# Persistence Layer (SQLModel) ---------------------------------------------------------
# --------------------------------------------------------------------------------------
class ObjectORM(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    name: str
    shape: str
    material: str
    state: str
    metadata: str  # JSON string

    @classmethod
    def from_symbolic(cls, obj: SymbolicObject) -> "ObjectORM":
        return cls(
            name=obj.name,
            shape=obj.shape.value,
            material=obj.material.value,
            state=obj.state.value,
            metadata=json.dumps(obj.metadata),
        )

    def to_symbolic(self) -> SymbolicObject:
        return SymbolicObject(
            name=self.name,
            shape=Shape(self.shape),
            material=Material(self.material),
            state=State(self.state),
            metadata=json.loads(self.metadata or "{}"),
        )


DB_URL_DEFAULT = "sqlite:///ake_substrate.db"
engine = create_engine(DB_URL_DEFAULT, echo=False, connect_args={"check_same_thread": False})
SQLModel.metadata.create_all(engine)

# --------------------------------------------------------------------------------------
# Texture Provider Protocol ------------------------------------------------------------
# --------------------------------------------------------------------------------------
class TextureProvider(Protocol):
    async def generate_texture(self, obj: SymbolicObject) -> str:  # noqa: D401
        ...


class OpenAIProvider:
    """Default provider that streams texture from OpenAI chat completion."""

    def __init__(self, *, model: str = "gpt-3.5-turbo", temperature: float = 0.8):
        if AsyncOpenAI is None:
            raise RuntimeError("openai python package is required for OpenAIProvider")
        self._client = AsyncOpenAI()
        self._model = model
        self._temperature = temperature

    async def generate_texture(self, obj: SymbolicObject) -> str:
        prompt = (
            "You are a sensory engine describing an object in vivid, poetic detail. "
            "Return exactly one sentence fragment (no period) that completes: \n"
            f"'{obj.material.value.title()} {obj.shape.value}'â€¦ based on its properties."
        )
        res = await self._client.chat.completions.create(
            model=self._model,
            temperature=self._temperature,
            messages=[{"role": "user", "content": prompt}],
        )
        return res.choices[0].message.content.strip().rstrip(".")


class StaticProvider:
    """Fallback provider using deterministic template (no external calls)."""

    _fallbacks: Dict[Material, List[str]] = {
        Material.CRYSTAL: ["shimmers with captured light"],
        Material.STONE: ["is rough and weathered"],
        Material.PLASMA: ["buzzes with raw energy"],
        Material.SILICON: ["gleams with artificial sheen"],
        Material.UNDEFINED: ["defies description"],
    }

    async def generate_texture(self, obj: SymbolicObject) -> str:  # noqa: D401
        choices = self._fallbacks.get(obj.material, ["has an indescribable texture"])
        return random.choice(choices)


# Active provider â€“ swap via env AKE_PROVIDER="static"/"openai"
PROVIDER: TextureProvider
if os.getenv("AKE_PROVIDER", "openai").lower() == "static":
    PROVIDER = StaticProvider()
else:
    try:
        PROVIDER = OpenAIProvider(model=os.getenv("AKE_MODEL", "gpt-3.5-turbo"))
    except Exception as exc:
        logger.warning("Falling back to StaticProvider: %s", exc)
        PROVIDER = StaticProvider()

# --------------------------------------------------------------------------------------
# Scene Renderer (REAL) ----------------------------------------------------------------
# --------------------------------------------------------------------------------------
class SceneRenderer:
    def __init__(self, *, rng_seed: Optional[int] = None):
        self.rng = random.Random(rng_seed)
        self.seed = rng_seed

    async def describe_object(self, obj: SymbolicObject) -> str:
        symbolic = obj.symbolic_str()
        neural = await PROVIDER.generate_texture(obj)
        sentence = f"[LOGIC CORE]: {symbolic}\n[NEURAL TEXTURE]: It {neural}.\n"
        return sentence

    async def describe_scene(self, objs: Iterable[SymbolicObject]) -> str:
        if not objs:
            return "The scene is empty."
        parts = await asyncio.gather(*(self.describe_object(o) for o in objs))
        return "--- SCENE REPORT ---\n" + "\n".join(parts) + "--- END REPORT ---"

# --------------------------------------------------------------------------------------
# FastAPI (REST / WS) ------------------------------------------------------------------
# --------------------------------------------------------------------------------------
app = FastAPI(title="AKE Neuroâ€‘Symbolic Engine", version="3.0.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # adjust in prod
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class SymbolicObjectIn(BaseModel):
    name: str
    shape: Shape = Shape.UNKNOWN
    material: Material = Material.UNDEFINED
    state: State = State.DEFAULT
    metadata: Dict[str, Any] = {}

    @validator("metadata", pre=True)
    def ensure_dict(cls, v: Any) -> Dict[str, Any]:  # noqa: N805
        return dict(v or {})


@app.on_event("startup")
async def startup_db() -> None:  # pragma: no cover
    logger.info("DB ready at %s", DB_URL_DEFAULT)


@app.post("/objects", response_model=SymbolicObjectIn)
async def create_object(obj: SymbolicObjectIn):
    sym = SymbolicObject(
        name=obj.name,
        shape=obj.shape,
        material=obj.material,
        state=obj.state,
        metadata=obj.metadata,
    )
    with Session(engine) as session:
        orm = ObjectORM.from_symbolic(sym)
        session.add(orm)
        session.commit()
        session.refresh(orm)
    return obj


@app.get("/scene", response_model=str)
async def render_scene(seed: Optional[int] = None):
    renderer = SceneRenderer(rng_seed=seed)
    with Session(engine) as session:
        objs = [row.to_symbolic() for row in session.exec(select(ObjectORM)).all()]
    return await renderer.describe_scene(objs)


# Simple broadcast hub for WebSocket clients ------------------------------------------
class ConnectionManager:
    def __init__(self):
        self.active: List[WebSocket] = []

    async def connect(self, ws: WebSocket):
        await ws.accept()
        self.active.append(ws)

    def disconnect(self, ws: WebSocket):
        self.active.remove(ws)

    async def broadcast(self, msg: str):
        for ws in list(self.active):
            try:
                await ws.send_text(msg)
            except WebSocketDisconnect:
                self.disconnect(ws)


autobroker = ConnectionManager()


@app.websocket("/ws/scene")
async def scene_ws(ws: WebSocket):
    await autobroker.connect(ws)
    try:
        while True:
            data = await ws.receive_json()
            cmd = data.get("cmd")
            if cmd == "render":
                seed = data.get("seed")
                desc = await render_scene(seed)  # type: ignore[arg-type]
                await ws.send_text(desc)
    except WebSocketDisconnect:
        autobroker.disconnect(ws)

# --------------------------------------------------------------------------------------
# CLI ---------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------
async def cli_main(argv: Sequence[str] | None = None) -> None:
    parser = argparse.ArgumentParser("AKE Engine v3 â€“ Realâ€‘World Edition")
    parser.add_argument("--serve", action="store_true", help="Run FastAPI server")
    parser.add_argument("--host", default="127.0.0.1")
    parser.add_argument("--port", type=int, default=8000)
    parser.add_argument("--seed", type=int, help="Render a oneâ€‘off scene and exit")
    parser.add_argument("--config", type=Path, help="Load objects from config into DB then exit")
    parser.add_argument("-v", "--verbose", action="count", default=0)
    args = parser.parse_args(argv)

    level_map = {0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG}
    logging.getLogger().setLevel(level_map.get(args.verbose, logging.DEBUG))

    # Preload objects if requested ----------------------------------------------------
    if args.config:
        objs = load_objects_from_file(args.config)
        with Session(engine) as session:
            session.add_all([ObjectORM.from_symbolic(o) for o in objs])
            session.commit()
        logger.info("Loaded %d objects from %s", len(objs), args.config)
        if not args.serve and args.seed is None:
            return

    if args.serve:
        import uvicorn

        uvicorn.run(app, host=args.host, port=args.port, log_level="info")
        return

    # Oneâ€‘off render ------------------------------------------------------------------
    if args.seed is not None:
        renderer = SceneRenderer(rng_seed=args.seed)
        with Session(engine) as session:
            objs = [row.to_symbolic() for row in session.exec(select(ObjectORM)).all()]
        print(await renderer.describe_scene(objs))
        return

    parser.print_help()


# --------------------------------------------------------------------------------------
# Config Loader -----------------------------------------------------------------------
# --------------------------------------------------------------------------------------

def load_objects_from_file(path: Path) -> List[SymbolicObject]:
    if not path.exists():
        raise FileNotFoundError(path)
    if path.suffix.lower() in {".yml", ".yaml"}:
        if yaml is None:
            raise RuntimeError("pyyaml required for YAML configs. Install it.")
        data = yaml.safe_load(path.read_text())
    else:
        data = json.loads(path.read_text())

    objs: List[SymbolicObject] = []
    for item in data.get("objects", []):
        objs.append(
            SymbolicObject(
                name=item["name"],
                shape=Shape(item.get("shape", Shape.UNKNOWN.value)),
                material=Material(item.get("material", Material.UNDEFINED.value)),
                state=State(item.get("state", State.DEFAULT.value)),
                metadata=item.get("metadata", {}),
            )
        )
    return objs

# --------------------------------------------------------------------------------------
# Entrypoint --------------------------------------------------------------------------
# --------------------------------------------------------------------------------------
if __name__ == "__main__":  # pragma: no cover
    try:
        asyncio.run(cli_main())
    except KeyboardInterrupt:
        logger.warning("Interrupted by user")
